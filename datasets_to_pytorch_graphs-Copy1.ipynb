{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "import uproot\n",
    "\n",
    "from create_train_test_dataset import scale_data, gen_bricks\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\r\n"
     ]
    }
   ],
   "source": [
    "!cd tools/ && python setup_opera_distance_metric.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.opera_distance_metric import generate_k_nearest_graph, opera_distance_metric_py, generate_radius_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 0, 0, 0, 0.])\n",
    "assert np.allclose(opera_distance_metric_py(a, \n",
    "                                         a + np.array([0, 0, 0, 3, 0, 0])), \n",
    "                   0)\n",
    "assert np.allclose(opera_distance_metric_py(a, \n",
    "                                         a + np.array([0, 0, 2, 3, 0, 0])), \n",
    "                   6 / 1293)\n",
    "assert np.allclose(opera_distance_metric_py(a, \n",
    "                                         a + np.array([0, 1, 2, 3, 0, 0])), \n",
    "                   np.sqrt(1 + 2**2) * 3 / 1293)\n",
    "assert np.allclose(opera_distance_metric_py(a, \n",
    "                                         a + np.array([0, 0, 0, 3, 1e-1, 0])), \n",
    "                   1e-1 * 3**2 / 2 / 1293, atol=1e-3, rtol=1e-4)\n",
    "assert np.allclose(opera_distance_metric_py(a, \n",
    "                                         a + np.array([0, 0, 0, 3, 1e-1, 1e-2])), \n",
    "                   np.sqrt(0.1**2 + 0.01**2) * 3**2 / 2 / 1293, atol=1e-3, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.sicara.com/fast-custom-knn-sklearn-cython-de92e5a325c\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mc(filename=\"./EM_data/mcdata_taue2.root\", step=1):\n",
    "    f = uproot.open(filename)\n",
    "    mc = f['Data'].pandas.df([\"Event_id\", \"ele_P\", \"BT_X\", \"BT_Y\",\n",
    "                              \"BT_Z\",\"BT_SX\", \"BT_SY\",\"ele_x\", \n",
    "                              \"ele_y\", \"ele_z\", \"ele_sx\", \"ele_sy\", \"chisquare\", ], flatten=False)\n",
    "    pmc = pd.DataFrame(mc)\n",
    "    pmc['numtracks'] = pmc.BT_X.apply(lambda x: len(x))\n",
    "    # cuts\n",
    "    shapechange = [pmc.shape[0]]\n",
    "    pmc = pmc[pmc.ele_P > 0.1]\n",
    "    shapechange.append(pmc.shape[0])\n",
    "\n",
    "    pmc = pmc[pmc.ele_z < 0]\n",
    "    shapechange.append(pmc.shape[0])\n",
    "\n",
    "    pmc = pmc[pmc.numtracks > 3]\n",
    "    shapechange.append(pmc.shape[0])\n",
    "    print(\"numtracks reduction by cuts: \", shapechange)\n",
    "    pmc['m_BT_X'] = pmc.BT_X.apply(lambda x: x.mean())\n",
    "    pmc['m_BT_Y'] = pmc.BT_Y.apply(lambda x: x.mean())\n",
    "    pmc['m_BT_Z'] = pmc.BT_Z.apply(lambda x: x.mean())\n",
    "\n",
    "    print(\"len(pmc): {len}\".format(len=len(pmc)))\n",
    "    return pmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numtracks reduction by cuts:  [18724, 18679, 9616, 9106]\n",
      "len(pmc): 9106\n"
     ]
    }
   ],
   "source": [
    "pmc = load_mc(filename='./EM_data/mcdata_taue2.root', step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmc_to_ship_format(pmc):\n",
    "    showers = []\n",
    "    scale = 10000\n",
    "    for idx in pmc.index:\n",
    "        shower = pmc.loc[idx]\n",
    "        \n",
    "        showers.append(\n",
    "            {\n",
    "                'TX': shower['BT_X'] / scale,\n",
    "                'TY': shower['BT_Y'] / scale,\n",
    "                'TZ': shower['BT_Z'] / scale,\n",
    "                'PX': shower['BT_SX'],\n",
    "                'PY': shower['BT_SY'],\n",
    "                'PZ': np.ones_like(shower['BT_X']),\n",
    "                'ele_P': shower['ele_P'],\n",
    "                'ele_TX': shower['ele_x'] / scale,\n",
    "                'ele_TY': shower['ele_y'] / scale,\n",
    "                'ele_TZ': shower['ele_z']  / scale,\n",
    "                'ele_PX': shower['ele_sx'],\n",
    "                'ele_PY': shower['ele_sy'],\n",
    "                'ele_PZ': 1.\n",
    "            }\n",
    "        )\n",
    "    return showers\n",
    "selected_showers = pmc_to_ship_format(pmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_showers = scale_data(pmc)\n",
    "selected_showers = [selected_shower for selected_shower in selected_showers if len(selected_shower['PX']) > 70]\n",
    "selected_showers = [selected_shower for selected_shower in selected_showers if len(selected_shower['PX']) < 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_showers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bricks = []\n",
    "NUM_SHOWERS_IN_BRICK = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 2.68 s, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scale = 10000\n",
    "bricks = []\n",
    "for i in range(len(selected_showers) // NUM_SHOWERS_IN_BRICK):\n",
    "    node_id = 0\n",
    "    graphx = nx.DiGraph()\n",
    "    nodes_to_add = []\n",
    "    showers_data = []\n",
    "    for j in range(NUM_SHOWERS_IN_BRICK):\n",
    "        selected_shower = selected_showers[i * NUM_SHOWERS_IN_BRICK + j]\n",
    "        showers_data.append(\n",
    "            {\n",
    "            'numtracks': len(selected_shower['PX']),\n",
    "            'signal': j,\n",
    "            'ele_P': selected_shower['ele_P'],\n",
    "            'ele_SX': selected_shower['ele_TX'] * scale,\n",
    "            'ele_SY': selected_shower['ele_TY'] * scale,\n",
    "            'ele_SZ': selected_shower['ele_TZ'] * scale,\n",
    "            'ele_TX': selected_shower['ele_PX'] / selected_shower['ele_PZ'],\n",
    "            'ele_TY': selected_shower['ele_PY'] / selected_shower['ele_PZ']\n",
    "            }\n",
    "        )\n",
    "        for k in range(len(selected_shower['PX'])):\n",
    "            nodes_to_add.append(\n",
    "                (\n",
    "                    node_id,\n",
    "                    {\n",
    "                        'features': {\n",
    "                            'SX': selected_shower['TX'][k] * scale,\n",
    "                            'SY': selected_shower['TY'][k] * scale,\n",
    "                            'SZ': selected_shower['TZ'][k] * scale,\n",
    "                            'TX': selected_shower['PX'][k] / selected_shower['PZ'][k],\n",
    "                            'TY': selected_shower['PY'][k] / selected_shower['PZ'][k],\n",
    "                        },\n",
    "                        'signal': j\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            node_id += 1\n",
    "    graphx.add_nodes_from(nodes_to_add)\n",
    "    graphx.graph['showers_data'] = showers_data\n",
    "    bricks.append(graphx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bricks = gen_bricks(selected_showers=selected_showers, NUM_SHOWERS_IN_BRICK=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103926 103926 103926 103926 103926 200 200\n",
      "[317, 152, 520, 119, 105, 615, 409, 77, 285, 163, 87, 564, 574, 127, 1508, 989, 144, 895, 294, 134, 685, 539, 1285, 358, 404, 717, 468, 430, 117, 1050, 723, 509, 627, 476, 102, 475, 103, 106, 889, 315, 506, 400, 703, 244, 241, 79, 103, 317, 833, 287, 1495, 1075, 650, 335, 374, 620, 1207, 607, 571, 109, 1588, 378, 1802, 118, 220, 107, 343, 516, 305, 342, 1154, 280, 859, 489, 1122, 506, 545, 152, 1120, 184, 368, 827, 258, 589, 726, 349, 139, 174, 598, 786, 90, 162, 425, 865, 853, 149, 516, 375, 134, 128, 106, 170, 591, 210, 1886, 586, 638, 597, 518, 2127, 520, 87, 227, 568, 406, 213, 321, 160, 1138, 243, 537, 121, 148, 949, 1567, 663, 581, 87, 1379, 753, 416, 166, 497, 623, 1886, 266, 763, 186, 911, 1050, 445, 360, 460, 889, 431, 132, 257, 852, 316, 407, 292, 188, 167, 773, 452, 171, 630, 958, 2428, 389, 183, 310, 123, 230, 367, 109, 75, 139, 99, 724, 1173, 270, 472, 470, 172, 435, 188, 109, 915, 244, 175, 1510, 2405, 1342, 274, 208, 249, 97, 401, 219, 163, 708, 152, 458, 231, 480, 571, 432, 713, 620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, graph in tqdm(enumerate(bricks)):\n",
    "        \n",
    "        nodes = graph.nodes()\n",
    "        \n",
    "        SX = [node['features']['SX'] for node in nodes.values()]\n",
    "        SY = [node['features']['SY'] for node in nodes.values()]\n",
    "        SZ = [node['features']['SZ'] for node in nodes.values()]\n",
    "        TX = [node['features']['TX'] for node in nodes.values()]\n",
    "        TY = [node['features']['TY'] for node in nodes.values()]\n",
    "        \n",
    "        \n",
    "        data = graph.graph\n",
    "\n",
    "        numtracks = [node['numtracks'] for node in data['showers_data']]\n",
    "        ele_P = [node['ele_P'] for node in data['showers_data']]\n",
    "        \n",
    "        \n",
    "        print(len(SX),len(SY),len(SZ),len(TX),len(TY), len(numtracks),len(ele_P))\n",
    "        \n",
    "        print(numtracks)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digraph_to_csv(graphs: list):\n",
    "    df = pd.DataFrame(columns=['brick_id', 'shower_id', 'SX', 'SY', 'SZ', 'TX', 'TY', \n",
    "                               \"ele_P\", \"BT_X\", \"BT_Y\",\n",
    "                               \"BT_Z\",\"BT_SX\", \"BT_SY\",\"ele_x\", \n",
    "                               \"ele_y\", \"ele_z\", \"ele_sx\", \"ele_sy\", 'shower_id', 'numtracks'])\n",
    "    \n",
    "    Numtracks = []\n",
    "    Ele_P = []\n",
    "    Ele_SX = []\n",
    "    Ele_SY = []\n",
    "    Ele_SZ = []\n",
    "    Ele_TX = []\n",
    "    Ele_TY = []\n",
    "    \n",
    "    for i, graph in tqdm(enumerate(graphs)):\n",
    "        data = graph.graph\n",
    "\n",
    "        numtracks = [node['numtracks'] for node in data['showers_data']]\n",
    "        ele_P = [node['ele_P'] for node in data['showers_data']]\n",
    "        ele_SX = [node['ele_SX'] for node in data['showers_data']]\n",
    "        ele_SY = [node['ele_SY'] for node in data['showers_data']]\n",
    "        ele_SZ = [node['ele_SZ'] for node in data['showers_data']]\n",
    "        ele_TX = [node['ele_TX'] for node in data['showers_data']]\n",
    "        ele_TY = [node['ele_TY'] for node in data['showers_data']]\n",
    "        \n",
    "        Numtracks.append(numtracks)\n",
    "        Ele_P.append(ele_P)\n",
    "        Ele_SX.append(ele_SX)\n",
    "        Ele_SY.append(ele_SY)\n",
    "        Ele_SZ.append(ele_SZ)\n",
    "        Ele_TX.append(ele_TX)\n",
    "        Ele_TY.append(ele_TY)\n",
    "        \n",
    "        \n",
    "        \n",
    "        nodes = graph.nodes()\n",
    "        \n",
    "        SX = [node['features']['SX'] for node in nodes.values()]\n",
    "        SY = [node['features']['SY'] for node in nodes.values()]\n",
    "        SZ = [node['features']['SZ'] for node in nodes.values()]\n",
    "        TX = [node['features']['TX'] for node in nodes.values()]\n",
    "        TY = [node['features']['TY'] for node in nodes.values()]\n",
    "        \n",
    "        \n",
    "        shower_id = [node['signal'] for node in nodes.values()]\n",
    "        brick_id = [i for _ in range(len(shower_id))]\n",
    "        \n",
    "        df = df.append(\n",
    "            pd.DataFrame(\n",
    "                {'brick_id': brick_id, \n",
    "                 'shower_id': shower_id, \n",
    "                 'SX': SX, \n",
    "                 'SY': SY, \n",
    "                 'SZ': SZ, \n",
    "                 'TX': TX, \n",
    "                 'TY': TY,\n",
    "                 \n",
    "                 'numtracks': numtracks, \n",
    "                 'ele_P': ele_P, \n",
    "                 'ele_SX': ele_SX, \n",
    "                 'ele_SY': ele_SY, \n",
    "                 'ele_SZ': ele_SZ, \n",
    "                 'ele_TX': ele_TX, \n",
    "                 'ele_TY': ele_TY,                 \n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph in tqdm(enumerate(bricks)):\n",
    "    data = graph.graph\n",
    "    #print(data.values())\n",
    "    numtracks = [node['numtracks'] for node in data['showers_data']]\n",
    "    print(len(numtracks))\n",
    "    \n",
    "    ele_P = [node['ele_P'] for node in data['showers_data']]\n",
    "    print(len(ele_P))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-02230ac8f1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigraph_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbricks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-9b2c2861e43f>\u001b[0m in \u001b[0;36mdigraph_to_csv\u001b[0;34m(graphs)\u001b[0m\n\u001b[1;32m     62\u001b[0m                  \u001b[0;34m'ele_SZ'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mele_SZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                  \u001b[0;34m'ele_TX'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mele_TX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                  \u001b[0;34m'ele_TY'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mele_TY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 }\n\u001b[1;32m     66\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df = digraph_to_csv(bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.loadtxt('./EM_data/opera_train.data')\n",
    "df = pd.DataFrame(df, columns=['brick_id', 'SX', 'SY', 'SZ', 'TX', 'TY'])\n",
    "\n",
    "df_sol = np.loadtxt('./EM_data/opera_train.solution')\n",
    "df_sol = pd.DataFrame(df_sol, columns=['brick_id', 'shower_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_torch_showers(df, df_sol, knn=False, r=250, k=5, directed=False, e = 0.00005):\n",
    "    showers = []\n",
    "\n",
    "    for brick_id in tqdm(list(df.brick_id.unique())[:]):\n",
    "        df_brick = df[df.brick_id == brick_id]\n",
    "        if knn:\n",
    "            edges_from, edge_to, dist = generate_k_nearest_graph(df_brick.values, \n",
    "                                                                 k, e=e,\n",
    "                                                                 symmetric=directed);\n",
    "            edges = np.vstack([edges_from, edge_to])\n",
    "            dist = np.array(dist)\n",
    "            edge_index = torch.LongTensor(edges)\n",
    "        else:\n",
    "            edges_from, edge_to, dist = generate_radius_graph(df_brick.values, \n",
    "                                                              r, e=e,\n",
    "                                                              symmetric=directed);\n",
    "            edges = np.vstack([edges_from, edge_to])\n",
    "            dist = np.array(dist)\n",
    "            edge_index = torch.LongTensor(edges)\n",
    "            \n",
    "        x = torch.FloatTensor(df_brick.values[:, 1:] / np.array([1e4, 1e4, 1e4, 1., 1.]))\n",
    "        edge_attr = torch.log(torch.FloatTensor(dist).view(-1, 1))\n",
    "        y = torch.LongTensor(df_sol.shower_id.loc[df_sol.brick_id == brick_id].values)\n",
    "        shower = torch_geometric.data.Data(x=x, edge_index=edge_index, \n",
    "                                           pos=x, edge_attr=edge_attr, y=y)\n",
    "        showers.append(shower)\n",
    "    \n",
    "    return showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showers_train=gen_torch_showers(df=df, df_sol=df_sol, knn=True, k=10, directed=False, e = 10)\n",
    "torch.save(showers_train, './EM_data/showers_trai7l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
