{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import pandas as pd\n",
    "#from comet_ml import Experiment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import click\n",
    "from nets import GraphNN_KNN_v1_v1, EdgeClassifier_v3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, accuracy_score, average_precision_score\n",
    "from torch_geometric.data import DataLoader\n",
    "from preprocessing1 import preprocess_dataset\n",
    "from utils import RunningAverageMeter, plot_aucs\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from hdbscan_ import run_hdbscan_on_brick, run_hdbscan\n",
    "import clustering_metrics\n",
    "from st_library_clustering_metrics import class_disbalance, class_disbalance__\n",
    "from st_library_clustering_metrics import estimate_start_xyz, estimate_txty\n",
    "from sklearn.linear_model import TheilSenRegressor, LinearRegression, HuberRegressor, RANSACRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import hdbscan\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_shower_(shower, graph_embedder, edge_classifier):\n",
    "    embeddings = graph_embedder(shower)\n",
    "    edge_labels_true = (shower.y[shower.edge_index[0]] == shower.y[shower.edge_index[1]]).view(-1)\n",
    "    edge_data = torch.cat([\n",
    "        embeddings[shower.edge_index[0]],\n",
    "        embeddings[shower.edge_index[1]]\n",
    "    ], dim=1)\n",
    "    \n",
    "    print(len(edge_data[0]))\n",
    "    for layer in edge_classifier._layers[:-4]:\n",
    "        print(layer)\n",
    "        edge_data = layer(edge_data)\n",
    "        print(len(edge_data[0]))\n",
    "    \n",
    "    \n",
    "    #edge_labels_predicted = edge_classifier(edge_data).view(-1)\n",
    "\n",
    "    return edge_labels_true, edge_data.view(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_shower(shower, graph_embedder, edge_classifier):\n",
    "    embeddings = graph_embedder(shower)\n",
    "    edge_labels_true = (shower.y[shower.edge_index[0]] == shower.y[shower.edge_index[1]]).view(-1)\n",
    "    edge_data = torch.cat([\n",
    "        embeddings[shower.edge_index[0]],\n",
    "        embeddings[shower.edge_index[1]]\n",
    "    ], dim=1)\n",
    "    edge_labels_predicted = edge_classifier(edge_data).view(-1)\n",
    "\n",
    "    return edge_labels_true, edge_labels_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_torch_shower_to_nx(shower, graph_embedder, edge_classifier, threshold=0.5):\n",
    "    node_id = 0\n",
    "    G = nx.DiGraph()\n",
    "    nodes_to_add = []\n",
    "    showers_data = []\n",
    "    y = shower.y.cpu().detach().numpy()\n",
    "    x = shower.x.cpu().detach().numpy()\n",
    "    y_torch = shower.y\n",
    "    for shower_id in tqdm(np.unique(y)):\n",
    "        shower_data = shower.shower_data[y_torch == shower_id].unique(dim=0).detach().cpu().numpy()[0]\n",
    "        showers_data.append(\n",
    "            {\n",
    "                'numtracks': shower_data[-2],\n",
    "                'signal': shower_id,\n",
    "                'ele_P': shower_data[0],\n",
    "                'ele_SX': shower_data[1],\n",
    "                'ele_SY': shower_data[2],\n",
    "                'ele_SZ': shower_data[3],\n",
    "                'ele_TX': shower_data[4],\n",
    "                'ele_TY': shower_data[5]\n",
    "            }\n",
    "        )\n",
    "    print(len(showers_data))\n",
    "    for k in range(len(y)):\n",
    "        nodes_to_add.append(\n",
    "            (\n",
    "                node_id,\n",
    "                {\n",
    "                    'features': {\n",
    "                        'SX': x[k, 0],\n",
    "                        'SY': x[k, 1],\n",
    "                        'SZ': x[k, 2],\n",
    "                        'TX': x[k, 3],\n",
    "                        'TY': x[k, 4],\n",
    "                    },\n",
    "                    'signal': y[k]\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        node_id += 1\n",
    "\n",
    "    edges_to_add = []\n",
    "    _, weights = predict_one_shower(shower, graph_embedder=graph_embedder, edge_classifier=edge_classifier)\n",
    "    weights = weights.detach().cpu().numpy()\n",
    "    \n",
    "    edge_index = shower.edge_index.t().detach().cpu().numpy()\n",
    "    edge_index = edge_index[weights > threshold]\n",
    "    weights = weights[weights > threshold]\n",
    "    weights = -np.log(weights) # TODO: which transformation to use?\n",
    "    print(len(weights))\n",
    "    for k, (p0, p1) in enumerate(edge_index):\n",
    "        edges_to_add.append((p0, p1, weights[k]))\n",
    "\n",
    "    G.add_nodes_from(nodes_to_add)\n",
    "    G.add_weighted_edges_from(edges_to_add)\n",
    "\n",
    "    G.graph['showers_data'] = showers_data\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_clustering_metrics(clusterized_brick):\n",
    "    selected_tracks = 0\n",
    "    total_tracks = 0\n",
    "\n",
    "    number_of_lost_showers = 0\n",
    "    number_of_broken_showers = 0\n",
    "    number_of_stucked_showers = 0\n",
    "    total_number_of_showers = 0\n",
    "    number_of_good_showers = 0\n",
    "    number_of_survived_showers = 0\n",
    "    second_to_first_ratios = []\n",
    "\n",
    "    E_raw = deque()\n",
    "    E_true = deque()\n",
    "\n",
    "    x_raw = deque()\n",
    "    x_true = deque()\n",
    "\n",
    "    y_raw = deque()\n",
    "    y_true = deque()\n",
    "\n",
    "    z_raw = deque()\n",
    "    z_true = deque()\n",
    "\n",
    "    tx_raw = deque()\n",
    "    tx_true = deque()\n",
    "\n",
    "    ty_raw = deque()\n",
    "    ty_true = deque()\n",
    "    \n",
    "    showers_data = G.graph['showers_data']\n",
    "    for shower_data in showers_data:\n",
    "            shower_data['clusters'] = []\n",
    "\n",
    "    \n",
    "    for i in range(len(clusters)):\n",
    "        cluster = clusters[i]\n",
    "        selected_tracks += len(cluster)\n",
    "        for label, label_count in class_disbalance(cluster):\n",
    "                if label_count/showers_data[label]['numtracks'] >= 0.1:\n",
    "                    showers_data[label]['clusters'].append(cluster)\n",
    "     \n",
    "\n",
    "    for i, shower_data in enumerate(showers_data):\n",
    "        total_tracks += shower_data['numtracks']\n",
    "        \n",
    "\n",
    "    for shower_data in showers_data:\n",
    "        total_number_of_showers += 1\n",
    "\n",
    "        signals_per_cluster = []\n",
    "        idx_cluster = []\n",
    "        for i, cluster in enumerate(shower_data['clusters']):\n",
    "            labels, counts = class_disbalance__(cluster)\n",
    "            signals_per_cluster.append(counts[labels == shower_data['signal']][0])\n",
    "            idx_cluster.append(i)\n",
    "            \n",
    "        signals_per_cluster = np.array(signals_per_cluster)\n",
    "        idx_cluster = np.array(idx_cluster)\n",
    "        second_to_first_ratio = 0.\n",
    "\n",
    "        if len(signals_per_cluster) == 0:\n",
    "            number_of_lost_showers += 1\n",
    "            continue\n",
    "        if len(signals_per_cluster) == 1:\n",
    "            second_to_first_ratio = 0.\n",
    "            second_to_first_ratios.append(second_to_first_ratio)\n",
    "        else:\n",
    "            second_to_first_ratio = np.sort(signals_per_cluster)[-2] / signals_per_cluster.max()\n",
    "            second_to_first_ratios.append(second_to_first_ratio)\n",
    "\n",
    "        cluster = shower_data['clusters'][np.argmax(signals_per_cluster)]\n",
    "\n",
    "            # not enough signal\n",
    "        if (signals_per_cluster.max() / shower_data['numtracks']) <= 0.1:\n",
    "            continue\n",
    "\n",
    "        labels, counts = class_disbalance__(cluster)\n",
    "\n",
    "        counts = counts / counts.sum()\n",
    "       \n",
    "            # high contamination\n",
    "        if counts[labels == shower_data['signal']] < 0.9:\n",
    "            number_of_stucked_showers += 1\n",
    "            continue\n",
    "\n",
    "        if second_to_first_ratio > 0.3:\n",
    "            number_of_broken_showers += 1\n",
    "            continue\n",
    "\n",
    "        # for good showers\n",
    "        number_of_good_showers += 1\n",
    "        \n",
    "        # E\n",
    "        E_raw.append(len(cluster))\n",
    "        E_true.append(shower_data['ele_P'])\n",
    "\n",
    "            # x, y, z\n",
    "        x, y, z = estimate_start_xyz(cluster)\n",
    "\n",
    "        x_raw.append(x)\n",
    "        x_true.append(shower_data['ele_SX'])\n",
    "\n",
    "        y_raw.append(y)\n",
    "        y_true.append(shower_data['ele_SY'])\n",
    "\n",
    "        z_raw.append(z)\n",
    "        z_true.append(shower_data['ele_SZ'])\n",
    "\n",
    "            # tx, ty\n",
    "        tx, ty = estimate_txty(cluster)\n",
    "\n",
    "        tx_raw.append(tx)\n",
    "        tx_true.append(shower_data['ele_TX'])\n",
    "\n",
    "        ty_raw.append(ty)\n",
    "        ty_true.append(shower_data['ele_TY'])\n",
    "\n",
    "    E_raw = np.array(E_raw)\n",
    "    E_true = np.array(E_true)\n",
    "\n",
    "    x_raw = np.array(x_raw)\n",
    "    x_true = np.array(x_true)\n",
    "\n",
    "    y_raw = np.array(y_raw)\n",
    "    y_true = np.array(y_true)\n",
    "\n",
    "    z_raw = np.array(z_raw)\n",
    "    z_true = np.array(z_true)\n",
    "\n",
    "    tx_raw = np.array(tx_raw)\n",
    "    tx_true = np.array(tx_true)\n",
    "\n",
    "    ty_raw = np.array(ty_raw)\n",
    "    ty_true = np.array(ty_true)\n",
    "\n",
    "\n",
    "    # Split a dataset into k folds\n",
    "    def cross_validation_split(dataset, folds=2):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / folds)\n",
    "        for i in range(folds):\n",
    "            fold = list()\n",
    "            while len(fold) < fold_size:\n",
    "                index = randrange(len(dataset_copy))\n",
    "                fold.append(dataset_copy.pop(index))\n",
    "            dataset_split.append(fold)\n",
    "        return dataset_split\n",
    "\n",
    "    # test cross validation split\n",
    "    seed(1)\n",
    "    dataset = E_raw.reshape((-1, 1))\n",
    "    print(dataset.shape)\n",
    "    folds = cross_validation_split(dataset, 2)\n",
    "    y = cross_validation_split(E_true, 2)\n",
    "    print(len(folds))\n",
    "    \n",
    "    len_X = 0\n",
    "    E_pred = []\n",
    "    for i in range(len(folds)):\n",
    "        folds_ = folds.copy()\n",
    "        y_ = y.copy()\n",
    "        \n",
    "        r = HuberRegressor()\n",
    "        X = folds_.pop(i)\n",
    "        Y = y_.pop(i)\n",
    "        \n",
    "        len_X+=len(X)      \n",
    "        \n",
    "        \n",
    "        folds_new = np.array([item for sublist in folds_ for item in sublist])\n",
    "        y_new = np.array([item for sublist in y_ for item in sublist])\n",
    "\n",
    "        r.fit(folds_new, y_new, sample_weight=1/(y_new)**6)\n",
    "        \n",
    "        Y_pred = r.predict(X)              \n",
    "        E_pred.append(Y_pred)\n",
    "\n",
    "   \n",
    "    E_pred = np.array(E_pred).reshape((-1, 1))\n",
    "    E_true = np.array(y).reshape((-1, 1)) \n",
    "    scale_mm = 10000\n",
    "    Energy_resolution = np.std((E_true - E_pred) / E_true)\n",
    "    print('Energy_resolution:', Energy_resolution)\n",
    "    Track_efficiency = selected_tracks / total_tracks\n",
    "    Good_showers = number_of_good_showers / total_number_of_showers\n",
    "    Stuck_showers = number_of_stucked_showers / total_number_of_showers\n",
    "    Broken_showers = number_of_broken_showers / total_number_of_showers\n",
    "    Lost_showers =number_of_lost_showers / total_number_of_showers\n",
    "    MAE_x = np.abs((x_raw * scale_mm - x_true) / scale_mm).mean()\n",
    "    MAE_y = np.abs((y_raw * scale_mm - y_true) / scale_mm).mean()\n",
    "    MAE_z = np.abs((z_raw * scale_mm - z_true) / scale_mm).mean()\n",
    "    MAE_tx = np.abs((tx_raw - tx_true)).mean()\n",
    "    MAE_ty = np.abs((ty_raw - ty_true)).mean()\n",
    "    \n",
    "    return Energy_resolution,Track_efficiency,Good_showers,Stuck_showers,Broken_showers,Lost_showers,MAE_x,MAE_y,MAE_z,MAE_tx,MAE_ty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "datafile='./data/train.pt'\n",
    "\n",
    "project_name='em_showers_clustering'\n",
    "work_space='ketrint'\n",
    "\n",
    "#experiment = Experiment('6O55PoJt4tkp9LyupIE86eikH', project_name=project_name, workspace=work_space)\n",
    "device = torch.device('cpu')\n",
    "showers = preprocess_dataset(datafile)\n",
    "\n",
    "k = showers[0].x.shape[1]\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_out=10\n",
    "threshold =0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeClassifier_v3(\n",
       "  (_layers): ModuleList(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.3)\n",
       "    (3): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.3)\n",
       "    (6): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): Dropout(p=0.3)\n",
       "    (9): Linear(in_features=10, out_features=1, bias=True)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_embedder = GraphNN_KNN_v1_v1(dim_out=dim_out, k=k).to(device)\n",
    "edge_classifier = EdgeClassifier_v3(dim_out=dim_out)\n",
    "\n",
    "graph_embedder.load_state_dict(torch.load('graph_embedder_v1_v1v3.pt', map_location=device))\n",
    "graph_embedder.eval()\n",
    "edge_classifier.load_state_dict(torch.load('edge_classifier_v1_v1v3.pt', map_location=device))\n",
    "edge_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 210.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "867869\n"
     ]
    }
   ],
   "source": [
    "G = preprocess_torch_shower_to_nx(showers[10],\n",
    "                                            graph_embedder=graph_embedder,\n",
    "                                            edge_classifier=edge_classifier,\n",
    "                                            threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112305, 10)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = showers[10].x.detach().numpy()\n",
    "y = showers[10].y.detach().numpy().reshape(-1,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112305, 1)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_id = np.arange(data.shape[0]).reshape(-1,1)\n",
    "node_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=200, random_state=0).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.predict(data).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112305, 8)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data = np.hstack((node_id, data[:,:5],labels, y))\n",
    "whole_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for node_id, SX, SY, SZ, TX, TY, key, y in whole_data:\n",
    "\n",
    "    clusters[key].append(\n",
    "            \n",
    "                {    \n",
    "                    'features': {\n",
    "                        'SX': SX,\n",
    "                        'SY': SY,\n",
    "                        'SZ': SZ,\n",
    "                        'TX': TX,\n",
    "                        'TY': TY,\n",
    "                    },\n",
    "                    'signal': int(y),\n",
    "                    'node_id': int(node_id),\n",
    "                }\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 230.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "797595\n",
      "Brick N: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:00<00:00, 219.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [1.0937959]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [1.812693]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.36156797800514756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 217.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "835667\n",
      "Brick N: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:00<00:00, 247.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [11.62014]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [13.702604]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.012878458651186007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 231.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "812690\n",
      "Brick N: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:00<00:00, 229.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [3.6352756]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [3.3270884]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.24192488371714027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 250.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "715753\n",
      "Brick N: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:00<00:00, 186.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [8.396688]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [5.421699]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.6227900303158156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 204.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "881207\n",
      "Brick N: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:00<00:00, 209.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [9.911651]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [2.4051852]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 2.2904200871533567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 215.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "847880\n",
      "Brick N: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [00:00<00:00, 228.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [18.772476]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [6.613272]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.15072058051307025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 223.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "843864\n",
      "Brick N: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:00<00:00, 198.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [2.6880145]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [2.8149016]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.1051075520582235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 208.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "859376\n",
      "Brick N: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:00<00:00, 248.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [5.086825]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [5.4884534]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.07501708009656036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 213.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "884671\n",
      "Brick N: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:00<00:00, 205.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [5.9202957]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [2.6488354]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 1.1073510628857282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 214.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "853312\n",
      "Brick N: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:00<00:00, 246.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [7.451229]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [5.115943]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.5516501547437712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 213.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "867869\n",
      "Brick N: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:00<00:00, 250.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [8.817481]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [11.976575]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.1560889176819083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 237.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "778521\n",
      "Brick N: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:00<00:00, 246.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [6.806085]\n",
      "0.0\n",
      "len(X) 1\n",
      "folds_new 1 [[428]]\n",
      "y_new 1 [9.891028]\n",
      "0.0\n",
      "2\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "Energy_resolution: 0.2249186578364497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 239.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "778062\n",
      "Brick N: 12\n",
      "(2, 1)\n",
      "2\n",
      "len(X) 1\n",
      "folds_new 1 [[368]]\n",
      "y_new 1 [0.7673867]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-389-085c15704785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Brick N:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mEnergy_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrack_efficiency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGood_showers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStuck_showers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBroken_showers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLost_showers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_tx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_ty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_clustering_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterized_brick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mEnergy_resolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergy_resolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-384-e30d7a36c6ee>\u001b[0m in \u001b[0;36mcalc_clustering_metrics\u001b[0;34m(clusterized_brick)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'folds_new'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_new'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/sklearn/linear_model/huber.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    291\u001b[0m             raise ValueError(\"HuberRegressor convergence failed:\"\n\u001b[1;32m    292\u001b[0m                              \u001b[0;34m\" l-BFGS-b solver terminated with %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                              % dict_['task'].decode('ascii'))\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# In scipy <= 1.0.0, nit may exceed maxiter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# See https://github.com/scipy/scipy/issues/7854.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH"
     ]
    }
   ],
   "source": [
    "Energy_resolutions = []\n",
    "Track_efficiencys = []\n",
    "Good_showerss = []\n",
    "Stuck_showerss = []\n",
    "Broken_showerss = [] \n",
    "Lost_showerss = []\n",
    "MAE_xs = []\n",
    "MAE_ys = []\n",
    "MAE_zs = []\n",
    "MAE_txs = []\n",
    "MAE_tys = []\n",
    "\n",
    "\n",
    "for i in range(40):\n",
    "    \n",
    "    brick = showers[i]\n",
    "    \n",
    "    G = preprocess_torch_shower_to_nx(brick,\n",
    "                                            graph_embedder=graph_embedder,\n",
    "                                            edge_classifier=edge_classifier,\n",
    "                                            threshold=threshold)\n",
    "    \n",
    "    \n",
    "    data = brick.x.detach().numpy()\n",
    "    y = brick.y.detach().numpy().reshape(-1,1)\n",
    "    node_id = np.arange(data.shape[0]).reshape(-1,1)\n",
    "    \n",
    "    #clusterization    \n",
    "    kmeans = MiniBatchKMeans(n_clusters=200, random_state=0).fit(data)\n",
    "    labels = kmeans.predict(data).reshape(-1,1)\n",
    "    \n",
    "    #data\n",
    "    whole_data = np.hstack((node_id, data[:,:5],labels, y))\n",
    "    \n",
    "    #add data to clusters information\n",
    "    clusterized_brick = defaultdict(list)\n",
    "    \n",
    "    for node_id, SX, SY, SZ, TX, TY, key, y in whole_data:\n",
    "\n",
    "        clusterized_brick[key].append(\n",
    "\n",
    "                    {    \n",
    "                        'features': {\n",
    "                            'SX': SX,\n",
    "                            'SY': SY,\n",
    "                            'SZ': SZ,\n",
    "                            'TX': TX,\n",
    "                            'TY': TY,\n",
    "                        },\n",
    "                        'signal': int(y),\n",
    "                        'node_id': int(node_id),\n",
    "                    }\n",
    "\n",
    "        )\n",
    "\n",
    "    \n",
    "    print('Brick N:', i)\n",
    "\n",
    "    Energy_resolution,Track_efficiency,Good_showers,Stuck_showers,Broken_showers,Lost_showers,MAE_x,MAE_y,MAE_z,MAE_tx,MAE_ty = calc_clustering_metrics(clusterized_brick)\n",
    "    \n",
    "    Energy_resolutions.append(Energy_resolution)\n",
    "    Track_efficiencys.append(Track_efficiency)\n",
    "    Good_showerss.append(Good_showers)\n",
    "    Stuck_showerss.append(Stuck_showers)\n",
    "    Broken_showerss.append(Broken_showers)\n",
    "    Lost_showerss.append(Lost_showers)\n",
    "    MAE_xs.append(MAE_x)\n",
    "    MAE_ys.append(MAE_y)\n",
    "    MAE_zs.append(MAE_z)\n",
    "    MAE_txs.append(MAE_tx)\n",
    "    MAE_tys.append(MAE_ty)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(np.column_stack([Energy_resolutions,\n",
    "    Track_efficiencys,\n",
    "    Good_showerss,\n",
    "    Stuck_showerss,\n",
    "    Broken_showerss,\n",
    "    Lost_showerss,\n",
    "    MAE_xs,\n",
    "    MAE_ys,\n",
    "    MAE_zs,\n",
    "    MAE_txs,\n",
    "    MAE_tys]), columns=['Energy_resolution', 'Track_efficiency', 'Good_showers', 'Stuck_showers',\n",
    "    'Broken_showers', 'Lost_showers', 'MAE_x', 'MAE_y', 'MAE_z', 'MAE_tx', 'MAE_ty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_resolution</th>\n",
       "      <th>Track_efficiency</th>\n",
       "      <th>Good_showers</th>\n",
       "      <th>Stuck_showers</th>\n",
       "      <th>Broken_showers</th>\n",
       "      <th>Lost_showers</th>\n",
       "      <th>MAE_x</th>\n",
       "      <th>MAE_y</th>\n",
       "      <th>MAE_z</th>\n",
       "      <th>MAE_tx</th>\n",
       "      <th>MAE_ty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.491703</td>\n",
       "      <td>1.041283</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>5.180038</td>\n",
       "      <td>1.904850</td>\n",
       "      <td>1996.665746</td>\n",
       "      <td>6.431110</td>\n",
       "      <td>9.756493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.644342</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>1.811860e-18</td>\n",
       "      <td>0.049970</td>\n",
       "      <td>1.811860e-18</td>\n",
       "      <td>0.049970</td>\n",
       "      <td>2.808737</td>\n",
       "      <td>1.331663</td>\n",
       "      <td>0.539777</td>\n",
       "      <td>0.060986</td>\n",
       "      <td>0.093151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.974185</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045490</td>\n",
       "      <td>0.197429</td>\n",
       "      <td>1995.926593</td>\n",
       "      <td>6.319961</td>\n",
       "      <td>9.635412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.139317</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>3.074574</td>\n",
       "      <td>0.886123</td>\n",
       "      <td>1996.298148</td>\n",
       "      <td>6.409748</td>\n",
       "      <td>9.693611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.233422</td>\n",
       "      <td>1.020186</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>5.780158</td>\n",
       "      <td>1.632048</td>\n",
       "      <td>1996.648143</td>\n",
       "      <td>6.428668</td>\n",
       "      <td>9.725091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.569435</td>\n",
       "      <td>1.078338</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>6.594023</td>\n",
       "      <td>2.475262</td>\n",
       "      <td>1997.008583</td>\n",
       "      <td>6.453920</td>\n",
       "      <td>9.839800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.290420</td>\n",
       "      <td>1.195077</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>9.549434</td>\n",
       "      <td>4.429449</td>\n",
       "      <td>1997.634832</td>\n",
       "      <td>6.562537</td>\n",
       "      <td>9.928096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Energy_resolution  Track_efficiency  Good_showers  Stuck_showers  \\\n",
       "count          12.000000         12.000000  1.200000e+01      12.000000   \n",
       "mean            0.491703          1.041283  1.000000e-02       0.833333   \n",
       "std             0.644342          0.063902  1.811860e-18       0.049970   \n",
       "min             0.012878          0.974185  1.000000e-02       0.790000   \n",
       "25%             0.139317          0.998663  1.000000e-02       0.812500   \n",
       "50%             0.233422          1.020186  1.000000e-02       0.815000   \n",
       "75%             0.569435          1.078338  1.000000e-02       0.832500   \n",
       "max             2.290420          1.195077  1.000000e-02       0.980000   \n",
       "\n",
       "       Broken_showers  Lost_showers      MAE_x      MAE_y        MAE_z  \\\n",
       "count    1.200000e+01     12.000000  12.000000  12.000000    12.000000   \n",
       "mean     1.000000e-02      0.146667   5.180038   1.904850  1996.665746   \n",
       "std      1.811860e-18      0.049970   2.808737   1.331663     0.539777   \n",
       "min      1.000000e-02      0.000000   0.045490   0.197429  1995.926593   \n",
       "25%      1.000000e-02      0.147500   3.074574   0.886123  1996.298148   \n",
       "50%      1.000000e-02      0.165000   5.780158   1.632048  1996.648143   \n",
       "75%      1.000000e-02      0.167500   6.594023   2.475262  1997.008583   \n",
       "max      1.000000e-02      0.190000   9.549434   4.429449  1997.634832   \n",
       "\n",
       "          MAE_tx     MAE_ty  \n",
       "count  12.000000  12.000000  \n",
       "mean    6.431110   9.756493  \n",
       "std     0.060986   0.093151  \n",
       "min     6.319961   9.635412  \n",
       "25%     6.409748   9.693611  \n",
       "50%     6.428668   9.725091  \n",
       "75%     6.453920   9.839800  \n",
       "max     6.562537   9.928096  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
