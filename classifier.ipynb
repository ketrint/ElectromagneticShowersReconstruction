{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import click\n",
    "from nets import GraphNN_KNN_v3, EdgeClassifier_v3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, accuracy_score, average_precision_score\n",
    "from torch_geometric.data import DataLoader\n",
    "from preprocessing import preprocess_dataset\n",
    "from utils import RunningAverageMeter, plot_aucs\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from st_library_clustering_metrics import class_disbalance, class_disbalance__\n",
    "from st_library_clustering_metrics import estimate_start_xyz, estimate_txty\n",
    "from sklearn.linear_model import TheilSenRegressor, LinearRegression, HuberRegressor, RANSACRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import sys\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import hdbscan\n",
    "\n",
    "from loss import FocalLoss\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping_:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, embeder, classifier, experiment_key):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, embeder, classifier, experiment_key)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, embeder, classifier, experiment_key)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, embeder, classifier, experiment_key):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(embeder.state_dict(), \"graph_embedder_{}.pt\".format(experiment_key))\n",
    "        torch.save(classifier.state_dict(), \"edge_classifier_{}.pt\".format(experiment_key))\n",
    "        self.val_loss_min = val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_class(classname: str):\n",
    "    \"\"\"\n",
    "    Function to get class object by its name signature\n",
    "    :param classname: str\n",
    "        name of the class\n",
    "    :return: class object with the same name signature as classname\n",
    "    \"\"\"\n",
    "    return getattr(sys.modules[__name__], classname)\n",
    "\n",
    "\n",
    "def predict_one_shower(shower, graph_embedder, edge_classifier):\n",
    "    # TODO: batch training\n",
    "    embeddings = graph_embedder(shower)\n",
    "    edge_labels_true = (shower.y[shower.edge_index[0]] == shower.y[shower.edge_index[1]]).view(-1)\n",
    "    edge_data = torch.cat([\n",
    "        embeddings[shower.edge_index[0]],\n",
    "        embeddings[shower.edge_index[1]]\n",
    "    ], dim=1)\n",
    "    edge_labels_predicted = edge_classifier(edge_data).view(-1)\n",
    "\n",
    "    return edge_labels_true, edge_labels_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_torch_shower_to_nx(shower, graph_embedder, edge_classifier, threshold=0.5):\n",
    "    node_id = 0\n",
    "    G = nx.DiGraph()\n",
    "    nodes_to_add = []\n",
    "    showers_data = []\n",
    "    y = shower.y.cpu().detach().numpy()\n",
    "    x = shower.x.cpu().detach().numpy()\n",
    "    y_torch = shower.y\n",
    "    for shower_id in tqdm(np.unique(y)):\n",
    "        shower_data = shower.shower_data[y_torch == shower_id].unique(dim=0).detach().cpu().numpy()[0]\n",
    "        #numtracks\\tsignal\\tele_P\\tele_SX\\tele_SY\\tele_SZ\\tele_TX\\tele_TY\"\n",
    "        showers_data.append(\n",
    "            {\n",
    "                'numtracks': shower_data[0],\n",
    "                'signal': shower_id,\n",
    "                'ele_P': shower_data[2],\n",
    "                'ele_SX': shower_data[3],\n",
    "                'ele_SY': shower_data[4],\n",
    "                'ele_SZ': shower_data[5],\n",
    "                'ele_TX': shower_data[6],\n",
    "                'ele_TY': shower_data[7]\n",
    "            }\n",
    "        )\n",
    "    print(len(showers_data))\n",
    "    for k in range(len(y)):\n",
    "        nodes_to_add.append(\n",
    "            (\n",
    "                node_id,\n",
    "                {\n",
    "                    'features': {\n",
    "                        'SX': x[k, 0],\n",
    "                        'SY': x[k, 1],\n",
    "                        'SZ': x[k, 2],\n",
    "                        'TX': x[k, 3],\n",
    "                        'TY': x[k, 4],\n",
    "                    },\n",
    "                    'signal': y[k]\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        node_id += 1\n",
    "\n",
    "    edges_to_add = []\n",
    "    _, weights = predict_one_shower(shower, graph_embedder=graph_embedder, edge_classifier=edge_classifier)\n",
    "    weights = weights.detach().cpu().numpy()\n",
    "    \n",
    "    edge_index = shower.edge_index.t().detach().cpu().numpy()\n",
    "    edge_index = edge_index[weights > threshold]\n",
    "    weights = weights[weights > threshold]\n",
    "    weights = -np.log(weights) # TODO: which transformation to use?\n",
    "    print(len(weights))\n",
    "    for k, (p0, p1) in enumerate(edge_index):\n",
    "        edges_to_add.append((p0, p1, weights[k]))\n",
    "\n",
    "    G.add_nodes_from(nodes_to_add)\n",
    "    G.add_weighted_edges_from(edges_to_add)\n",
    "\n",
    "    G.graph['showers_data'] = showers_data\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "datafile='train1.pt'\n",
    "\n",
    "project_name='em-showers-network-training'\n",
    "work_space='ketrint'\n",
    "\n",
    "experiment = Experiment('6O55PoJt4tkp9LyupIE86eikH', project_name=project_name, workspace=work_space)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "showers = preprocess_dataset(datafile)\n",
    "\n",
    "k = showers[0].x.shape[1]\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "learning_rate=1e-3\n",
    "dim_out=10\n",
    "threshold =0.9\n",
    "\n",
    "graph_embedder='GraphNN_KNN_v3'\n",
    "edge_classifier='EdgeClassifier_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_attr=[4574767, 1], edge_index=[2, 4574767], mask=[58, 4574767], pos=[103926, 5], shower_data=[200, 8], x=[103926, 10], y=[103926]),\n",
       " Data(edge_attr=[4806582, 1], edge_index=[2, 4806582], mask=[58, 4806582], pos=[108505, 5], shower_data=[200, 8], x=[108505, 10], y=[108505]),\n",
       " Data(edge_attr=[4096292, 1], edge_index=[2, 4096292], mask=[58, 4096292], pos=[104220, 5], shower_data=[200, 8], x=[104220, 10], y=[104220])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "showers_train, showers_test = train_test_split(showers, random_state=1337)\n",
    "\n",
    "train_loader = DataLoader(showers_train, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(showers_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embedder = str_to_class(graph_embedder)(dim_out=dim_out, k=k).to(device)\n",
    "edge_classifier = str_to_class(edge_classifier)(dim_out=dim_out).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(gamma=2.)\n",
    "optimizer = torch.optim.Adam(list(graph_embedder.parameters()) + list(edge_classifier.parameters()),\n",
    "                             lr=learning_rate)\n",
    "\n",
    "loss_train = RunningAverageMeter()\n",
    "loss_test = RunningAverageMeter()\n",
    "roc_auc_test = RunningAverageMeter()\n",
    "pr_auc_test = RunningAverageMeter()\n",
    "acc_test = RunningAverageMeter()\n",
    "class_disbalance = RunningAverageMeter()\n",
    "\n",
    "experiment = Experiment('6O55PoJt4tkp9LyupIE86eikH', project_name=project_name, workspace=work_space)\n",
    "early_stopping = EarlyStopping_(patience=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([103926, 10]) torch.Size([2, 4574767]) torch.Size([4574767, 1])\n",
      "torch.Size([4574767, 10]) 4574767\n",
      "torch.Size([103926, 10]) torch.Size([2, 4574767]) torch.Size([4574767, 1])\n",
      "torch.Size([4574767, 10]) 4574767\n",
      "torch.Size([103926, 10]) torch.Size([2, 4574767]) torch.Size([4574767, 1])\n",
      "torch.Size([4574767, 10]) 4574767\n",
      "torch.Size([108505, 10]) torch.Size([2, 4806582]) torch.Size([4806582, 1])\n",
      "torch.Size([4806582, 10]) 4806582\n",
      "torch.Size([108505, 10]) torch.Size([2, 4806582]) torch.Size([4806582, 1])\n",
      "torch.Size([4806582, 10]) 4806582\n",
      "torch.Size([108505, 10]) torch.Size([2, 4806582]) torch.Size([4806582, 1])\n",
      "torch.Size([4806582, 10]) 4806582\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 11.17 GiB total capacity; 5.84 GiB already allocated; 488.81 MiB free; 6.39 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ef7bcd689b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 11.17 GiB total capacity; 5.84 GiB already allocated; 488.81 MiB free; 6.39 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(epochs)):\n",
    "    for shower in train_loader:\n",
    "            shower = shower.to(device)\n",
    "            edge_labels_true, edge_labels_predicted = predict_one_shower(shower,\n",
    "                                                                         graph_embedder=graph_embedder,\n",
    "                                                                         edge_classifier=edge_classifier)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(edge_labels_predicted, edge_labels_true.float())\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train.update(loss.item())\n",
    "            class_disbalance.update((edge_labels_true.sum().float() / len(edge_labels_true)).item())\n",
    "\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    for shower in test_loader:\n",
    "            shower = shower.to(device)\n",
    "            edge_labels_true, edge_labels_predicted = predict_one_shower(shower,\n",
    "                                                                         graph_embedder=graph_embedder,\n",
    "                                                                         edge_classifier=edge_classifier)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(edge_labels_predicted, edge_labels_true.float())\n",
    "            y_true, y_pred = edge_labels_true.detach().cpu().numpy(), edge_labels_predicted.detach().cpu().numpy()\n",
    "            y_true_list.append(y_true)\n",
    "            y_pred_list.append(y_pred)\n",
    "            acc = accuracy_score(y_true, y_pred.round())\n",
    "            roc_auc = roc_auc_score(y_true, y_pred)\n",
    "            pr_auc = average_precision_score(y_true, y_pred)\n",
    "            loss_test.update(loss.item())\n",
    "            acc_test.update(acc)\n",
    "            roc_auc_test.update(roc_auc)\n",
    "            pr_auc_test.update(pr_auc)\n",
    "            class_disbalance.update((edge_labels_true.sum().float() / len(edge_labels_true)).item())\n",
    "\n",
    "\n",
    "    \n",
    "    experiment_key = experiment.get_key()\n",
    "\n",
    "    eval_loss = loss_test.val\n",
    "    early_stopping(eval_loss, graph_embedder, edge_classifier, experiment_key)\n",
    "\n",
    "\n",
    "    if early_stopping.early_stop:\t\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    experiment.log_metric('loss_test', loss_test.val)\t\n",
    "    experiment.log_metric('acc_test', acc_test.val)\n",
    "    experiment.log_metric('roc_auc_test', roc_auc_test.val)\n",
    "    experiment.log_metric('pr_auc_test', pr_auc_test.val)\n",
    "    experiment.log_metric('class_disbalance', class_disbalance.val)\n",
    "\n",
    "    y_true = np.concatenate(y_true_list)\n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "# load the last checkpoint with the best model\n",
    "\t\n",
    "graph_embedder.load_state_dict(torch.load(\"graph_embedder_{}.pt\".format(experiment_key)))\n",
    "edge_classifier.load_state_dict(torch.load(\"edge_classifier_{}.pt\".format(experiment_key)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
